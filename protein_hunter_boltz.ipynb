{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30ed923f",
   "metadata": {},
   "source": [
    "## Protein Hunter Boltz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b62b0d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[14:44:51] Initializing Normalizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Core functionality imported.\n"
     ]
    }
   ],
   "source": [
    "# @title üß© Setup and Core Imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import contextlib\n",
    "import io\n",
    "import copy\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# Suppress warnings for a cleaner output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly.*\",\n",
    "    category=UserWarning,\n",
    ")\n",
    "\n",
    "import py2Dmol\n",
    "from LigandMPNN.wrapper import LigandMPNNWrapper\n",
    "\n",
    "from boltz_ph.constants import CHAIN_TO_NUMBER\n",
    "from utils.metrics import get_CA_and_sequence # Used implicitly in design.py\n",
    "from utils.convert import calculate_holo_apo_rmsd, convert_cif_files_to_pdb\n",
    "# -----------------------------\n",
    "\n",
    "from boltz_ph.model_utils import (\n",
    "    binder_binds_contacts,\n",
    "    extract_sequence_from_structure,\n",
    "    clean_memory,\n",
    "    design_sequence,\n",
    "    get_boltz_model,\n",
    "    get_cif,\n",
    "    load_canonicals,\n",
    "    plot_from_pdb,\n",
    "    plot_run_metrics,\n",
    "    process_msa,\n",
    "    run_prediction,\n",
    "    sample_seq,\n",
    "    save_pdb,\n",
    "    shallow_copy_tensor_dict,\n",
    "    smart_split,\n",
    ")\n",
    "print(\"‚úÖ Core functionality imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471e67bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title üß¨ Boltz Configuration Parameters\n",
    "# --- General Setup ---\n",
    "gpu_id = 0  # @param {type:\"integer\"}\n",
    "ligand_gpu_id = gpu_id  # @param {type:\"integer\"}  # Set to -1 to run LigandMPNN on CPU or choose another GPU\n",
    "grad_enabled = False  # @param {type:\"boolean\"}\n",
    "name = \"PDL1_SAM_binder\"  # @param {type:\"string\"}\n",
    "mode = \"binder\"  # @param [\"unconditional\", \"binder\"]\n",
    "num_designs = 3  # @param {type:\"integer\"}\n",
    "num_cycles = 5  # @param {type:\"integer\"}\n",
    "\n",
    "save_dir = f\"./results_boltz/{name}\"\n",
    "work_dir = os.getcwd()\n",
    "\n",
    "# --- Sequence Length ---\n",
    "min_protein_length = 100  # @param {type:\"integer\"}\n",
    "max_protein_length = 150  # @param {type:\"integer\"}\n",
    "cyclic = False  # @param {type:\"boolean\"}\n",
    "\n",
    "# --- Target Protein(s) ---\n",
    "protein_seqs = \"FTVTVPKDLYVVEYGSNMTIECKFPVEKQLDLAALIVYWEMEDKNIIQFVHGEEDLKVQHSSYRQRARLLKDQLSLGNAALQITDVKLQDAGVYRCMISYGGADYKRITVKVNK\"  # @param {type:\"string\"}\n",
    "msa_mode = \"mmseqs\" # @param [\"single\", \"mmseqs\"]\n",
    "\n",
    "# --- Non-Protein Components (Ligand/Nucleic Acid) ---\n",
    "ligand_smiles = \"\"  # @param {type:\"string\"}\n",
    "ligand_ccd = \"SAM\"  # @param {type:\"string\"}\n",
    "\n",
    "nucleic_seq = \"\"  # @param {type:\"string\"}\n",
    "nucleic_type = \"dna\" # @param [\"dna\", \"rna\"]\n",
    "\n",
    "# --- Templates and Constraints ---\n",
    "template_path = \"\"\n",
    "template_cif_chain_id = \"\" # for mmCIF files, which chain from mmcif file to use for the template\n",
    "\n",
    "contact_residues = \"\" # @param {type:\"string\"}  # e.g., \"1,2,5,10\" on target chain \n",
    "#@markdown - Specify which target chain residues must contact the binder (currently only supports protein contacts). For more than two chains, separate by |, e.g., \"1,2,5,10 | 3,5,10\".\n",
    "\n",
    "contact_cutoff = 10.0\n",
    "max_contact_filter_retries = 6\n",
    "no_contact_filter = False\n",
    "\n",
    "# --- Model & Diffusion Parameters ---\n",
    "diffuse_steps = 200  # @param {type:\"integer\"}\n",
    "recycling_steps = 3  # @param {type:\"integer\"}\n",
    "boltz_model_version = \"boltz2\"  # @param [\"boltz1\", \"boltz2\"]\n",
    "boltz_model_path = os.path.expanduser(\"~/.boltz/boltz2_conf.ckpt\")\n",
    "ccd_path = Path(os.path.expanduser(\"~/.boltz/mols\"))\n",
    "logmd = False  # @param {type:\"boolean\"}\n",
    "\n",
    "# --- Design & Optimization ---\n",
    "randomly_kill_helix_feature = False  # @param {type:\"boolean\"}\n",
    "negative_helix_constant = 0.2  # @param {type:\"number\"}\n",
    "\n",
    "temperature = 0.1  # @param {type:\"number\"}\n",
    "alanine_bias = True  # @param {type:\"boolean\"}\n",
    "alanine_bias_start = -0.5  # @param {type:\"number\"}\n",
    "alanine_bias_end = -0.1  # @param {type:\"number\"}\n",
    "\n",
    "omit_AA = \"C\"  # @param {type:\"string\"}\n",
    "exclude_P = False  # @param {type:\"boolean\"}\n",
    "percent_X = 80  # @param {type:\"number\"}\n",
    "high_iptm_threshold = 0.8  # @param {type:\"number\"}\n",
    "high_plddt_threshold = 0.8  # @param {type:\"number\"}\n",
    "\n",
    "# --- Optional: Validation Parameters (External Dependencies) ---\n",
    "alphafold_dir = os.path.expanduser(\"~/alphafold3\")\n",
    "af3_docker_name = \"alphafold3_yc\"\n",
    "af3_database_settings = os.path.expanduser(\"~/alphafold3/alphafold3_data_save\")\n",
    "hmmer_path = os.path.expanduser(\"~/.conda/envs/alphafold3_venv\")\n",
    "use_msa_for_af3 = False\n",
    "plot = True  # @param {type:\"boolean\"}\n",
    "viewer = True  # @param {type:\"boolean\"}\n",
    "\n",
    "# Re-package parameters into an 'args' object (simple class for dot notation)\n",
    "class Args:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n",
    "\n",
    "args = Args(**locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dc89ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title ‚öôÔ∏è Initialize Models and Prepare Base Data\n",
    "# --- 1. Model Initialization ---\n",
    "device = (\n",
    "    f\"cuda:{args.gpu_id}\" if torch.cuda.is_available() and args.gpu_id >= 0 else \"cpu\"\n",
    ")\n",
    "print(f\"Using device: {device}\")\n",
    "ligand_design_gpu = (\n",
    "    args.ligand_gpu_id if args.ligand_gpu_id is not None else args.gpu_id\n",
    ")\n",
    "if ligand_design_gpu == -1:\n",
    "    print(\"LigandMPNN will run on CPU (no CUDA device).\")\n",
    "else:\n",
    "    print(f\"LigandMPNN will run on cuda:{ligand_design_gpu} for sequence design.\")\n",
    "\n",
    "\n",
    "predict_args = {\n",
    "    \"recycling_steps\": args.recycling_steps,\n",
    "    \"sampling_steps\": args.diffuse_steps,\n",
    "    \"diffusion_samples\": 1,\n",
    "    \"write_confidence_summary\": True,\n",
    "    \"write_full_pae\": False,\n",
    "    \"write_full_pde\": False,\n",
    "    \"max_parallel_samples\": 1,\n",
    "}\n",
    "\n",
    "ccd_lib = load_canonicals(os.path.expanduser(str(args.ccd_path)))\n",
    "boltz_model = get_boltz_model(\n",
    "    checkpoint=args.boltz_model_path,\n",
    "    predict_args=predict_args,\n",
    "    device=device,\n",
    "    model_version=args.boltz_model_version,\n",
    "    no_potentials=False if args.contact_residues else True,\n",
    "    \n",
    "    grad_enabled=args.grad_enabled,\n",
    ")\n",
    "designer = LigandMPNNWrapper(os.path.join(args.work_dir, \"./LigandMPNN/run.py\"))\n",
    "protein_hunter_save_dir = os.path.join(args.save_dir, \"0_protein_hunter_design\")\n",
    "os.makedirs(protein_hunter_save_dir, exist_ok=True)\n",
    "os.makedirs(args.save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# --- 2. Data Preparation (Condensed from _build_initial_data_dict) ---\n",
    "sequences = []\n",
    "\n",
    "# --- Process sequences and assign chain IDs ---\n",
    "args.binder_chain = \"A\"\n",
    "protein_seqs_list = smart_split(args.protein_seqs) if args.protein_seqs else []\n",
    "\n",
    "if args.msa_mode == \"single\":\n",
    "    protein_msas_list = [\"empty\"] * len(protein_seqs_list)\n",
    "elif args.msa_mode == \"mmseqs\":    \n",
    "    protein_msas_list = [\"mmseqs\"] * len(protein_seqs_list)\n",
    "else:\n",
    "    raise ValueError(f\"Invalid msa_mode: {args.msa_mode}\")\n",
    "# Assign chain IDs\n",
    "protein_chain_ids = [chr(ord('B') + i) for i in range(len(protein_seqs_list))]\n",
    "next_chain_idx = len(protein_chain_ids)\n",
    "\n",
    "ligand_chain_id = None\n",
    "if args.ligand_smiles or args.ligand_ccd:\n",
    "    ligand_chain_id = chr(ord('B') + next_chain_idx)\n",
    "    next_chain_idx += 1\n",
    "    \n",
    "nucleic_chain_id = None\n",
    "if args.nucleic_seq:\n",
    "    nucleic_chain_id = chr(ord('B') + next_chain_idx)\n",
    "    next_chain_idx += 1\n",
    "# --- END MODIFICATIONS ---\n",
    "\n",
    "seq_to_indices = defaultdict(list)\n",
    "for idx, seq in enumerate(protein_seqs_list):\n",
    "    if seq:\n",
    "        seq_to_indices[seq].append(idx)\n",
    "seq_to_final_msa = {}\n",
    "\n",
    "# Suppress MSA generation output during this phase\n",
    "print(\"Processing MSAs (if any)...\")\n",
    "with contextlib.redirect_stdout(io.StringIO()) as f:\n",
    "    for seq, idx_list in seq_to_indices.items():\n",
    "        chosen_msa = next(\n",
    "            (\n",
    "                protein_msas_list[i]\n",
    "                for i in idx_list\n",
    "            ),\n",
    "            None,\n",
    "        )\n",
    "        if chosen_msa == \"mmseqs\":\n",
    "            pid = protein_chain_ids[idx_list[0]]\n",
    "            msa_value = process_msa(pid, seq, Path(protein_hunter_save_dir))\n",
    "            seq_to_final_msa[seq] = str(msa_value)\n",
    "        elif chosen_msa == \"empty\":\n",
    "            seq_to_final_msa[seq] = \"empty\"\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid msa_mode: {args.msa_mode}\")\n",
    "\n",
    "\n",
    "# Build sequences list\n",
    "for i, (seq, msa) in enumerate(zip(protein_seqs_list, protein_msas_list)):\n",
    "    if not seq:\n",
    "        continue\n",
    "    pid = protein_chain_ids[i]\n",
    "    final_msa = seq_to_final_msa.get(seq, \"empty\")\n",
    "    sequences.append(\n",
    "        {\"protein\": {\"id\": [pid], \"sequence\": seq, \"msa\": final_msa}}\n",
    "    )\n",
    "\n",
    "sequences.append(\n",
    "    {\n",
    "        \"protein\": {\n",
    "            \"id\": [\"A\"], # Binder is always 'A'\n",
    "            \"sequence\": \"X\",\n",
    "            \"msa\": \"empty\",\n",
    "            \"cyclic\": args.cyclic,\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "if args.ligand_smiles:\n",
    "    sequences.append({\"ligand\": {\"id\": [ligand_chain_id], \"smiles\": args.ligand_smiles}})\n",
    "elif args.ligand_ccd:\n",
    "    sequences.append({\"ligand\": {\"id\": [ligand_chain_id], \"ccd\": args.ligand_ccd}})\n",
    "if args.nucleic_seq:\n",
    "    sequences.append(\n",
    "        {args.nucleic_type: {\"id\": [nucleic_chain_id], \"sequence\": args.nucleic_seq}}\n",
    "    )\n",
    "\n",
    "# --- Handle templates with 1-to-1 mapping ---\n",
    "templates = []\n",
    "if args.template_path:\n",
    "    template_path_list = smart_split(args.template_path)\n",
    "    template_cif_chain_id_list = (\n",
    "        smart_split(args.template_cif_chain_id) if args.template_cif_chain_id else []\n",
    "    )\n",
    "    \n",
    "    num_proteins = len(protein_chain_ids)\n",
    "    \n",
    "    while len(template_path_list) < num_proteins:\n",
    "        template_path_list.append(\"\")\n",
    "    while len(template_cif_chain_id_list) < num_proteins:\n",
    "        template_cif_chain_id_list.append(\"\")\n",
    "\n",
    "    for i in range(num_proteins):\n",
    "        template_file_path = template_path_list[i]\n",
    "        if not template_file_path:\n",
    "            continue\n",
    "            \n",
    "        template_file = get_cif(template_file_path)\n",
    "        \n",
    "        t_block = (\n",
    "            {\"cif\": template_file}\n",
    "            if template_file.endswith(\".cif\")\n",
    "            else {\"pdb\": template_file}\n",
    "        )\n",
    "        \n",
    "        t_block[\"chain_id\"] = protein_chain_ids[i]\n",
    "        cif_chain = template_cif_chain_id_list[i]\n",
    "        if cif_chain:\n",
    "            t_block[\"cif_chain_id\"] = cif_chain\n",
    "\n",
    "        templates.append(t_block)\n",
    "\n",
    "data = {\"sequences\": sequences}\n",
    "if templates:\n",
    "    data[\"templates\"] = templates\n",
    "pocket_conditioning = bool(args.contact_residues and args.contact_residues.strip())\n",
    "\n",
    "if pocket_conditioning:\n",
    "    contacts = []\n",
    "    residues_chains = args.contact_residues.split(\"|\")\n",
    "    for i, residues_chain in enumerate(residues_chains):\n",
    "        residues = residues_chain.split(\",\")\n",
    "        contacts.extend([\n",
    "            [protein_chain_ids[i], int(res)]\n",
    "            for res in residues\n",
    "            if res.strip() != \"\"\n",
    "        ])\n",
    "    constraints = [{\"pocket\": {\"binder\": \"A\", \"contacts\": contacts}}]\n",
    "    data[\"constraints\"] = constraints\n",
    "    \n",
    "data[\"sequences\"] = sorted(\n",
    "    data[\"sequences\"], key=lambda entry: list(entry.values())[0][\"id\"][0]\n",
    ")\n",
    "any_ligand_or_nucleic = args.ligand_smiles or args.ligand_ccd or args.nucleic_seq\n",
    "model_type = \"ligand_mpnn\" if any_ligand_or_nucleic else \"soluble_mpnn\"\n",
    "\n",
    "print(\"‚úÖ Models ready and base data configured.\")\n",
    "print(\"Mode:\", args.mode)\n",
    "print(\"Data dictionary (base):\\n\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12d7f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title üöÄ Execute Design and Optimization Loop\n",
    "# Replicate the core logic from _run_design_cycle and run_pipeline's execution part\n",
    "import contextlib\n",
    "import io\n",
    "\n",
    "# NOTE: Using viewer object from global scope for incremental updates\n",
    "all_run_metrics = []\n",
    "\n",
    "for design_id in range(args.num_designs):\n",
    "    if viewer:\n",
    "        viewer = py2Dmol.view((600,400), color=\"plddt\")\n",
    "        viewer.show()\n",
    "\n",
    "    run_id = str(design_id)\n",
    "    run_save_dir = os.path.join(args.save_dir, f\"run_{run_id}\")\n",
    "    os.makedirs(run_save_dir, exist_ok=True)\n",
    "\n",
    "    data_cp = copy.deepcopy(data)\n",
    "\n",
    "    print(\"\\n=======================================================\")\n",
    "    print(f\"=== Starting Design Run {run_id}/{args.num_designs - 1} ===\")\n",
    "    print(\"=======================================================\")\n",
    "\n",
    "    best_iptm = float(\"-inf\")\n",
    "    best_seq = None\n",
    "    best_structure = None\n",
    "    best_output = None\n",
    "    best_pdb_filename = None\n",
    "    best_cycle_idx = -1\n",
    "    best_alanine_percentage = None\n",
    "    run_metrics = {\"run_id\": run_id}\n",
    "\n",
    "    # --- Initial Sequence Assignment ---\n",
    "    binder_length = random.randint(\n",
    "        args.min_protein_length, args.max_protein_length\n",
    "    )\n",
    "    new_seq = sample_seq(binder_length, exclude_P=args.exclude_P, frac_X=args.percent_X/100)\n",
    "\n",
    "    # Update binder sequence in the data dictionary copy\n",
    "    for seq_entry in data_cp[\"sequences\"]:\n",
    "        if \"protein\" in seq_entry and args.binder_chain in seq_entry[\"protein\"][\"id\"]:\n",
    "            seq_entry[\"protein\"][\"sequence\"] = new_seq\n",
    "            break\n",
    "    print(f\"Binder initial sequence length: {binder_length}\")\n",
    "\n",
    "    # ========== Cycle 0 structure prediction (with contact filtering) ==========\n",
    "    contact_filter_attempt = 0\n",
    "    pdb_filename = \"\"\n",
    "    structure = None\n",
    "    output = None\n",
    "\n",
    "    while True:\n",
    "        # SUPPRESS UNWANTED MSA MESSAGES during prediction\n",
    "        with contextlib.redirect_stdout(io.StringIO()) as f:\n",
    "            output, structure = run_prediction(\n",
    "                data_cp,\n",
    "                args.binder_chain,\n",
    "                randomly_kill_helix_feature=args.randomly_kill_helix_feature,\n",
    "                negative_helix_constant=args.negative_helix_constant,\n",
    "                boltz_model=boltz_model,\n",
    "                ccd_lib=ccd_lib,\n",
    "                ccd_path=args.ccd_path,\n",
    "                logmd=args.logmd,\n",
    "                device=device,\n",
    "                boltz_model_version=args.boltz_model_version,\n",
    "                pocket_conditioning=pocket_conditioning,\n",
    "            )\n",
    "\n",
    "        # Save Cycle 0 PDB\n",
    "        pdb_filename = f\"{run_save_dir}/{args.name}_run_{run_id}_predicted_cycle_0.pdb\"\n",
    "        plddts = output[\"plddt\"].detach().cpu().numpy()[0]\n",
    "        save_pdb(structure, output[\"coords\"], plddts, pdb_filename)\n",
    "\n",
    "        # Contact filtering (only if configured)\n",
    "        contact_check_okay = True\n",
    "        if args.contact_residues.strip() and not args.no_contact_filter:\n",
    "            try:\n",
    "                binds = all(\n",
    "                    binder_binds_contacts(\n",
    "                        pdb_filename,\n",
    "                        args.binder_chain,\n",
    "                        protein_chain_ids[i],\n",
    "                        contact_res,\n",
    "                        cutoff=args.contact_cutoff,\n",
    "                    )\n",
    "                    for i, contact_res in enumerate(args.contact_residues.split(\"|\"))\n",
    "                )\n",
    "                if not binds:\n",
    "                    print(\"‚ùå Binder does NOT contact required residues after cycle 0. Retrying...\")\n",
    "                    contact_check_okay = False\n",
    "            except Exception as e:\n",
    "                print(f\"WARNING: Could not perform binder-contact check: {e}\")\n",
    "                contact_check_okay = True\n",
    "\n",
    "        if contact_check_okay:\n",
    "            break\n",
    "        else:\n",
    "            contact_filter_attempt += 1\n",
    "            if contact_filter_attempt >= args.max_contact_filter_retries:\n",
    "                print(\"‚ö†Ô∏è Maximum contact filter retries reached. Proceeding anyway.\")\n",
    "                break\n",
    "\n",
    "            # Resample initial sequence\n",
    "            new_seq = sample_seq(\n",
    "                binder_length, exclude_P=args.exclude_P, frac_X=args.percent_X/100\n",
    "            )\n",
    "            for seq_entry in data_cp[\"sequences\"]:\n",
    "                if (\n",
    "                    \"protein\" in seq_entry\n",
    "                    and args.binder_chain in seq_entry[\"protein\"][\"id\"]\n",
    "                ):\n",
    "                    seq_entry[\"protein\"][\"sequence\"] = new_seq\n",
    "                    break\n",
    "            clean_memory()\n",
    "\n",
    "    # --- Capture Cycle 0 metrics (same logic as before) ---\n",
    "    binder_chain_idx = CHAIN_TO_NUMBER[args.binder_chain]\n",
    "    pair_chains = output[\"pair_chains_iptm\"]\n",
    "    if len(pair_chains) > 1:\n",
    "        values = [\n",
    "            (\n",
    "                pair_chains[binder_chain_idx][i].detach().cpu().numpy()\n",
    "                + pair_chains[i][binder_chain_idx].detach().cpu().numpy()\n",
    "            )\n",
    "            / 2.0\n",
    "            for i in range(len(pair_chains))\n",
    "            if i != binder_chain_idx\n",
    "        ]\n",
    "        cycle_0_iptm = float(np.mean(values) if values else 0.0)\n",
    "    else:\n",
    "        cycle_0_iptm = 0.0\n",
    "    run_metrics[\"cycle_0_iptm\"] = cycle_0_iptm\n",
    "    run_metrics[\"cycle_0_plddt\"] = float(\n",
    "        output.get(\"complex_plddt\", torch.tensor([0.0])).detach().cpu().numpy()[0]\n",
    "    )\n",
    "    run_metrics[\"cycle_0_iplddt\"] = float(\n",
    "        output.get(\"complex_iplddt\", torch.tensor([0.0])).detach().cpu().numpy()[0]\n",
    "    )\n",
    "    run_metrics[\"cycle_0_alanine\"] = 0\n",
    "    run_metrics[\"cycle_0_seq\"] = new_seq\n",
    "\n",
    "    # ===== Optimization Cycles (Cycle 1 to num_cycles) =====\n",
    "    for cycle in range(args.num_cycles):\n",
    "        print(f\"\\n--- Run {run_id}, Cycle {cycle + 1} ---\")\n",
    "\n",
    "        # Calculate temperature and bias\n",
    "        cycle_norm = (cycle / (args.num_cycles - 1)) if args.num_cycles > 1 else 0.0\n",
    "        alpha = args.alanine_bias_start - cycle_norm * (\n",
    "            args.alanine_bias_start - args.alanine_bias_end\n",
    "        )\n",
    "        temperature = args.temperature\n",
    "        design_kwargs = {\n",
    "            \"pdb_file\": pdb_filename,\n",
    "            \"temperature\": temperature,\n",
    "            \"chains_to_design\": args.binder_chain,\n",
    "            \"omit_AA\": f\"{args.omit_AA},P\" if cycle == 0 else args.omit_AA,\n",
    "        }\n",
    "        if args.alanine_bias:\n",
    "            design_kwargs[\"bias_AA\"] = f\"A:{alpha}\"\n",
    "\n",
    "        seq_str, logits = design_sequence(\n",
    "            designer,\n",
    "            model_type,\n",
    "            ligand_gpu_id=ligand_design_gpu,\n",
    "            **design_kwargs,\n",
    "        )\n",
    "        seq = seq_str.split(\":\")[CHAIN_TO_NUMBER[args.binder_chain]]\n",
    "\n",
    "        alanine_count = seq.count(\"A\")\n",
    "        alanine_percentage = alanine_count / binder_length if binder_length else 0.0\n",
    "        for seq_entry in data_cp[\"sequences\"]:\n",
    "            if (\n",
    "                \"protein\" in seq_entry\n",
    "                and args.binder_chain in seq_entry[\"protein\"][\"id\"]\n",
    "            ):\n",
    "                seq_entry[\"protein\"][\"sequence\"] = seq\n",
    "                break\n",
    "\n",
    "        # SUPPRESS UNWANTED MSA MESSAGES during prediction\n",
    "        with contextlib.redirect_stdout(io.StringIO()) as f:\n",
    "            output, structure = run_prediction(\n",
    "                data_cp,\n",
    "                args.binder_chain,\n",
    "                seq=seq,\n",
    "                randomly_kill_helix_feature=False,\n",
    "                negative_helix_constant=0.0,\n",
    "                boltz_model=boltz_model,\n",
    "                ccd_lib=ccd_lib,\n",
    "                ccd_path=args.ccd_path,\n",
    "                logmd=False,\n",
    "                device=device,\n",
    "            )\n",
    "\n",
    "        # Compute ipTM\n",
    "        current_chain_idx = CHAIN_TO_NUMBER[args.binder_chain]\n",
    "        pair_chains = output[\"pair_chains_iptm\"]\n",
    "        if len(pair_chains) > 1:\n",
    "            values = [\n",
    "                (\n",
    "                    pair_chains[current_chain_idx][i].detach().cpu().numpy()\n",
    "                    + pair_chains[i][current_chain_idx].detach().cpu().numpy()\n",
    "                )\n",
    "                / 2.0\n",
    "                for i in range(len(pair_chains))\n",
    "                if i != current_chain_idx\n",
    "            ]\n",
    "            current_iptm = float(np.mean(values) if values else 0.0)\n",
    "        else:\n",
    "            current_iptm = 0.0\n",
    "\n",
    "        # Update best structure\n",
    "        if alanine_percentage <= 0.20 and current_iptm > best_iptm:\n",
    "            best_iptm = current_iptm\n",
    "            best_structure = copy.deepcopy(structure)\n",
    "            best_output = shallow_copy_tensor_dict(output)\n",
    "            best_pdb_filename = (\n",
    "                f\"{run_save_dir}/{args.name}_run_{run_id}_best_structure.pdb\"\n",
    "            )\n",
    "            best_plddts = best_output[\"plddt\"].detach().cpu().numpy()[0]\n",
    "            save_pdb(\n",
    "                best_structure, best_output[\"coords\"], best_plddts, best_pdb_filename\n",
    "            )\n",
    "            best_cycle_idx = cycle + 1\n",
    "            best_seq = seq\n",
    "            best_alanine_percentage = alanine_percentage\n",
    "\n",
    "        # Record metrics\n",
    "        curr_plddt = float(\n",
    "            output.get(\"complex_plddt\", torch.tensor([0.0])).detach().cpu().numpy()[0]\n",
    "        )\n",
    "        curr_iplddt = float(\n",
    "            output.get(\"complex_iplddt\", torch.tensor([0.0])).detach().cpu().numpy()[0]\n",
    "        )\n",
    "        run_metrics[f\"cycle_{cycle + 1}_iptm\"] = current_iptm\n",
    "        run_metrics[f\"cycle_{cycle + 1}_plddt\"] = curr_plddt\n",
    "        run_metrics[f\"cycle_{cycle + 1}_iplddt\"] = curr_iplddt\n",
    "        run_metrics[f\"cycle_{cycle + 1}_alanine\"] = alanine_count\n",
    "        run_metrics[f\"cycle_{cycle + 1}_seq\"] = seq\n",
    "\n",
    "        print(\n",
    "            f\"ipTM: {current_iptm:.2f}, pLDDT: {curr_plddt:.2f}, iPLDDT: {curr_iplddt:.2f}, Ala%: {alanine_percentage * 100:.1f}\"\n",
    "        )\n",
    "\n",
    "        pdb_filename = (\n",
    "            f\"{run_save_dir}/{args.name}_run_{run_id}_predicted_cycle_{cycle + 1}.pdb\"\n",
    "        )\n",
    "        plddts = output[\"plddt\"].detach().cpu().numpy()[0]\n",
    "        save_pdb(structure, output[\"coords\"], plddts, pdb_filename)\n",
    "\n",
    "        if viewer:\n",
    "            viewer.add_pdb(pdb_filename)\n",
    "        \n",
    "        # 4. Save YAML for High ipTM\n",
    "        save_yaml_this_design = (alanine_percentage <= 0.20) and (\n",
    "            current_iptm > high_iptm_threshold and curr_plddt > high_plddt_threshold\n",
    "        )\n",
    "        \n",
    "        if save_yaml_this_design and args.contact_residues.strip():\n",
    "            try:\n",
    "                contact_binds = all(\n",
    "                    binder_binds_contacts(\n",
    "                        pdb_filename,\n",
    "                        args.binder_chain,\n",
    "                        protein_chain_ids[i],\n",
    "                        contact_res,\n",
    "                        cutoff=args.contact_cutoff,\n",
    "                    )\n",
    "                    for i, contact_res in enumerate(args.contact_residues.split(\"|\"))\n",
    "                )\n",
    "                if not contact_binds:\n",
    "                    save_yaml_this_design = False\n",
    "                    print(\n",
    "                        \"‚õîÔ∏è Not saving YAML: binder failed contact check for high ipTM save.\"\n",
    "                    )\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"WARNING: Exception during contact check: {e}. Saving YAML anyway.\"\n",
    "                )\n",
    "\n",
    "        if save_yaml_this_design:\n",
    "            high_iptm_yaml_dir = os.path.join(args.save_dir, \"high_iptm_yaml\")\n",
    "            os.makedirs(high_iptm_yaml_dir, exist_ok=True)\n",
    "            yaml_filename = os.path.join(\n",
    "                high_iptm_yaml_dir,\n",
    "                f\"{args.name}_run_{run_id}_cycle_{cycle + 1}_output.yaml\",\n",
    "            )\n",
    "            with open(yaml_filename, \"w\") as f:\n",
    "                yaml.dump(data_cp, f, default_flow_style=False)\n",
    "            print(f\"‚úÖ Saved run {run_id} cycle {cycle + 1} YAML.\")\n",
    "\n",
    "\n",
    "        clean_memory()\n",
    "\n",
    "    # --- Finalize and Plot Metrics ---\n",
    "    run_metrics[\"best_iptm\"] = float(\n",
    "        best_iptm if best_iptm != float(\"-inf\") else np.nan\n",
    "    )\n",
    "    run_metrics[\"best_cycle\"] = best_cycle_idx\n",
    "    run_metrics[\"best_seq\"] = best_seq\n",
    "    if best_output:\n",
    "        run_metrics[\"best_plddt\"] = float(\n",
    "            best_output.get(\"complex_plddt\", torch.tensor([np.nan]))\n",
    "            .detach()\n",
    "            .cpu()\n",
    "            .numpy()[0]\n",
    "        )\n",
    "    else:\n",
    "        run_metrics[\"best_plddt\"] = np.nan\n",
    "    all_run_metrics.append(run_metrics)\n",
    "\n",
    "    if args.plot:\n",
    "        plot_run_metrics(run_save_dir, args.name, run_id, args.num_cycles, run_metrics)\n",
    "\n",
    "\n",
    "# ===== Save All Run Metrics to CSV =====\n",
    "summary_csv = os.path.join(args.save_dir, \"summary_all_runs.csv\")\n",
    "df = pd.DataFrame(all_run_metrics)\n",
    "columns = [\"run_id\"]\n",
    "for i in range(args.num_cycles + 1):\n",
    "    columns.extend(\n",
    "        [\n",
    "            f\"cycle_{i}_iptm\",\n",
    "            f\"cycle_{i}_plddt\",\n",
    "            f\"cycle_{i}_iplddt\",\n",
    "            f\"cycle_{i}_alanine\",\n",
    "            f\"cycle_{i}_seq\",\n",
    "        ]\n",
    "    )\n",
    "columns.extend([\"best_iptm\", \"best_cycle\", \"best_plddt\", \"best_seq\"])\n",
    "for col in columns:\n",
    "    if col not in df.columns:\n",
    "        df[col] = np.nan\n",
    "df = df[[c for c in columns if c in df.columns]]\n",
    "df.to_csv(summary_csv, index=False)\n",
    "print(f\"\\n‚úÖ All run/cycle metrics saved to {summary_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b19c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title ‚öôÔ∏è Optional: Downstream Validation (Requires External Setup)\n",
    "# Determine target type\n",
    "from utils.alphafold_utils import run_alphafold_step\n",
    "from utils.pyrosetta_utils import run_rosetta_step\n",
    "\n",
    "target_type = \"protein\"\n",
    "if args.nucleic_seq:\n",
    "    target_type = \"nucleic\"\n",
    "elif args.ligand_smiles or args.ligand_ccd:\n",
    "    target_type = \"small_molecule\"\n",
    "\n",
    "success_dir = os.path.join(args.save_dir, \"1_af3_rosetta_validation\")\n",
    "high_iptm_yaml_dir = os.path.join(args.save_dir, \"high_iptm_yaml\")\n",
    "\n",
    "# AlphaFold step\n",
    "af_output_dir, af_output_apo_dir, af_pdb_dir, af_pdb_dir_apo = run_alphafold_step(\n",
    "    high_iptm_yaml_dir,\n",
    "    args.alphafold_dir,\n",
    "    args.af3_docker_name,\n",
    "    args.af3_database_settings,\n",
    "    args.hmmer_path,\n",
    "    success_dir,\n",
    "    args.work_dir,\n",
    "    binder_id=args.binder_chain,\n",
    "    gpu_id=args.gpu_id,\n",
    "    high_iptm=True,\n",
    "    use_msa_for_af3=args.use_msa_for_af3,\n",
    ")\n",
    "\n",
    "# Rosetta step\n",
    "run_rosetta_step(\n",
    "    success_dir,\n",
    "    af_pdb_dir,\n",
    "    af_pdb_dir_apo,\n",
    "    binder_id=args.binder_chain,\n",
    "    target_type=target_type,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Pipeline execution complete. Check results in the output directory.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
